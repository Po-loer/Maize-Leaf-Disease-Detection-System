{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHwF1uCF4YWg"
      },
      "outputs": [],
      "source": [
        "#  Cell 1: Clean install & import libraries, mount Drive\n",
        "\n",
        "# Update pip first\n",
        "!pip install -U pip --quiet\n",
        "\n",
        "# Colab already includes tensorflow, matplotlib, sklearn, seaborn\n",
        "# We only need to add cv2 (opencv-python-headless) safely\n",
        "!pip install -q opencv-python-headless tensorflow_hub\n",
        "\n",
        "# Imports\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLClfR6ctRCa"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Load sample images and define utility for display\n",
        "# Correct path to your dataset inside Google Drive\n",
        "data_path = '/content/drive/MyDrive/Plant Disease segmentation/dataset1'\n",
        "\n",
        "# Utility function to display images\n",
        "def show_image(title, img, cmap=None):\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.title(title)\n",
        "    if cmap:\n",
        "        plt.imshow(img, cmap=cmap)\n",
        "    else:\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Automatically detect all class folders\n",
        "class_folders = [f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f))]\n",
        "\n",
        "print(\"Detected class folders:\", class_folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Army_Uld4hVC"
      },
      "outputs": [],
      "source": [
        "# Load and display one sample image per class\n",
        "for class_name in class_folders:\n",
        "    folder_path = os.path.join(data_path, class_name)\n",
        "    image_files = os.listdir(folder_path)\n",
        "    if len(image_files) == 0:\n",
        "        print(f\"No images found in {class_name}\")\n",
        "        continue\n",
        "    img_path = os.path.join(folder_path, image_files[0])\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is not None:\n",
        "        show_image(f\"Sample: {class_name}\", img)\n",
        "    else:\n",
        "        print(f\" Could not read image from {img_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ-msvoGok8V"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Part A - Grayscale, Adaptive thresholding, Morphological operations and contour detection\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# --- Utility: segmentation function ---\n",
        "def segment_leaf(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    thresh = cv2.adaptiveThreshold(\n",
        "        gray, 255,\n",
        "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY_INV,\n",
        "        11, 2\n",
        "    )\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "    return morph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8Vls_oKorHF"
      },
      "outputs": [],
      "source": [
        "# --- Select one healthy and one diseased sample for demonstration ---\n",
        "# NOTE: change these if you want different categories\n",
        "healthy_path = os.path.join(data_path, 'Healthy', os.listdir(os.path.join(data_path, 'Healthy'))[0])\n",
        "diseased_path = os.path.join(data_path, 'Common_Rust', os.listdir(os.path.join(data_path, 'Common_Rust'))[0])\n",
        "\n",
        "healthy_img = cv2.imread(healthy_path)\n",
        "diseased_img = cv2.imread(diseased_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo7JshPRoxej"
      },
      "outputs": [],
      "source": [
        "# --- Segment both images ---\n",
        "healthy_seg = segment_leaf(healthy_img)\n",
        "diseased_seg = segment_leaf(diseased_img)\n",
        "\n",
        "# --- Display segmented images ---\n",
        "show_image('Healthy Leaf Segmentation', healthy_seg, cmap='gray')\n",
        "show_image('Diseased Leaf Segmentation', diseased_seg, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm8JhA_ro8WP"
      },
      "outputs": [],
      "source": [
        "# --- Contour detection on diseased segmentation ---\n",
        "contours, _ = cv2.findContours(diseased_seg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "diseased_contours = diseased_img.copy()\n",
        "cv2.drawContours(diseased_contours, contours, -1, (0,255,0), 3)\n",
        "show_image('Diseased Leaf Contours', diseased_contours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmO6vC2Y4lW2"
      },
      "outputs": [],
      "source": [
        "# --- Calculate percentage of affected area ---\n",
        "affected_pixels = cv2.countNonZero(diseased_seg)\n",
        "total_pixels = diseased_seg.size\n",
        "percentage_affected = (affected_pixels / total_pixels) * 100\n",
        "print(f\"Percentage of affected leaf area: {percentage_affected:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3G1pI654oEK"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Part B - Prepare dataset for classification\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Recursive function to gather image paths and labels from dataset folders\n",
        "def load_dataset(base_path):\n",
        "    classes = sorted(os.listdir(base_path))\n",
        "    images = []\n",
        "    labels = []\n",
        "    for ix, cls in enumerate(classes):\n",
        "        cls_folder = os.path.join(base_path, cls)\n",
        "        for img_name in os.listdir(cls_folder):\n",
        "            img_path = os.path.join(cls_folder, img_name)\n",
        "            if img_path.endswith(('jpeg','jpg','png')):\n",
        "                images.append(img_path)\n",
        "                labels.append(cls)\n",
        "    return images, labels\n",
        "\n",
        "image_paths, labels = load_dataset(data_path)\n",
        "print(f\"Total images: {len(image_paths)} Classes: {set(labels)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naU9sabqoEAc"
      },
      "outputs": [],
      "source": [
        "# Encode labels to integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "labels_enc = le.fit_transform(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAP0Ybixn3vx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train/test split\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels_enc, test_size=0.2, stratify=labels_enc, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_paths)}  Test samples: {len(test_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki4jGH5t4rOJ"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Data generator for loading images on the fly\n",
        "\n",
        "IMG_SIZE = 224  # EfficientNetB0 input size\n",
        "\n",
        "def preprocess_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def data_generator(paths, labels, batch_size=32):\n",
        "    while True:\n",
        "        for i in range(0, len(paths), batch_size):\n",
        "            batch_paths = paths[i:i+batch_size]\n",
        "            batch_labels = labels[i:i+batch_size]\n",
        "            batch_images = np.array([preprocess_image(p) for p in batch_paths])\n",
        "            batch_labels_arr = np.array(batch_labels)\n",
        "            yield batch_images, batch_labels_arr\n",
        "\n",
        "train_gen = data_generator(train_paths, train_labels)\n",
        "test_gen = data_generator(test_paths, test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwqMenb64unb"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Build and compile EfficientNetB0 classification model\n",
        "\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False,\n",
        "                                                  input_shape=(IMG_SIZE, IMG_SIZE,3),\n",
        "                                                  pooling='avg',\n",
        "                                                  weights='imagenet')\n",
        "\n",
        "base_model.trainable = False  # Freeze base\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE,3))\n",
        "x = base_model(inputs, training=False)\n",
        "outputs = layers.Dense(len(set(labels)), activation='softmax')(x)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- New Cell: Calculate Class Weights ---\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# 1. Get unique classes and calculate balanced weights\n",
        "# train_labels is an array of integer-encoded labels (0, 1, 2, 3...)\n",
        "classes = np.unique(train_labels)\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=train_labels\n",
        ")\n",
        "\n",
        "# 2. Convert to the dictionary format required by Keras: {0: weight0, 1: weight1, ...}\n",
        "class_weights = dict(zip(classes, weights))\n",
        "\n",
        "print(\"Calculated Class Weights (Class Index: Weight):\")\n",
        "print(class_weights)\n",
        "print(\"Class Names:\", le.classes_) # To check the order, e.g., 0=Blight, 3=Healthy\n",
        "\n",
        "# The weight for 'Healthy' (the majority class) should be significantly < 1.0,\n",
        "# and the disease classes should be > 1.0."
      ],
      "metadata": {
        "id": "p0D3pVIuPL_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOEnLVWK4y2s"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Train model for 8-12 epochs\n",
        "\n",
        "EPOCHS = 10\n",
        "STEPS_PER_EPOCH = len(train_paths) // 32\n",
        "VALIDATION_STEPS = len(test_paths) // 32\n",
        "\n",
        "history = model.fit(train_gen,\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    validation_data=test_gen,\n",
        "                    validation_steps=VALIDATION_STEPS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw0xjJoNpltF"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Evaluate model: accuracy, F1-score, confusion matrix, classification report\n",
        "\n",
        "# Predict on test set\n",
        "test_batches = len(test_paths) // 32 + 1\n",
        "pred_probs = model.predict(test_gen, steps=test_batches)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels[:len(pred_labels)], pred_labels, target_names=le.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr20fWaJ411f"
      },
      "outputs": [],
      "source": [
        "f1 = f1_score(test_labels[:len(pred_labels)], pred_labels, average='weighted')\n",
        "print(f\"Weighted F1 Score: {f1:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(test_labels[:len(pred_labels)], pred_labels)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlsZWesV45Tx"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Visualize correctly vs incorrectly classified samples\n",
        "\n",
        "def visualize_results(paths, true_lbls, pred_lbls, class_names, num_samples=5):\n",
        "    correct = []\n",
        "    incorrect = []\n",
        "    for p, t, pr in zip(paths, true_lbls, pred_lbls):\n",
        "        if t == pr:\n",
        "            correct.append((p, t, pr))\n",
        "        else:\n",
        "            incorrect.append((p, t, pr))\n",
        "\n",
        "    print(f\"Correctly Classified Samples ({min(num_samples,len(correct))}):\")\n",
        "    for i in range(min(num_samples,len(correct))):\n",
        "        img = cv2.imread(correct[i][0])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"True: {class_names[correct[i][1]]} Pred: {class_names[correct[i][2]]}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    print(f\"Incorrectly Classified Samples ({min(num_samples,len(incorrect))}):\")\n",
        "    for i in range(min(num_samples,len(incorrect))):\n",
        "        img = cv2.imread(incorrect[i][0])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"True: {class_names[incorrect[i][1]]} Pred: {class_names[incorrect[i][2]]}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "visualize_results(test_paths[:len(pred_labels)], test_labels[:len(pred_labels)], pred_labels, le.classes_, num_samples=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D29Qt_o_49PS"
      },
      "outputs": [],
      "source": [
        "# Cell 10: Discussion - How segmentation helps interpretation\n",
        "\n",
        "print(\"\"\"\n",
        "Segmentation provides a focused region of interest by isolating diseased parts of the leaf. This helps the\n",
        "classification model to potentially learn more disease-specific features by ignoring healthy background regions.\n",
        "Moreover, segmentation serves as an explainability tool by highlighting affected areas, allowing users to visually\n",
        "confirm what parts contribute to the model's decisions. Integrating segmentation with classification improves\n",
        "interpretability and can guide more precise disease diagnosis and treatment in precision agriculture.\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
